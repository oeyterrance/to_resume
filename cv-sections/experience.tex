%----------------------------------------------------------------------------------------
%	SECTION TITLE
%----------------------------------------------------------------------------------------

\cvsection{Experience}

%----------------------------------------------------------------------------------------
%	SECTION CONTENT
%----------------------------------------------------------------------------------------

\begin{cventries}

%------------------------------------------------

\cventry
{Financial Analyst (Data Engineer) (CG-14)} % Job title
{Federal Deposit Insurance Corporation} % Organization
{Arlington, VA} % Location
{January 2022 - Present} % Date(s)
{ % Description(s) of tasks/responsibilities
\begin{cvitems}
\item {Leads and maintains the weekly Extract, Load, Transfer (ETL) process for over 100,000 rows of critical data, which is utilized by other analysts to determine fees to charge to financial institutions for insurance purposes.}
\item {Automated the creation of 100s of historical financial reports using Python (openpyxl/pandas) in 15 minutes that normally took the analyst over 20 hours of manual work to create using legacy tools (SAS/MS Access/Excel).}
\item {Utilized Power BI and SQL to automated a legacy financial product used across FDIC that originally used SAS, Access, and Excel.}
\item {Project managing and contributing to the creation and update of a GUI tool using Python, that helps analysts across FDIC to do complex data queries with simple button clicks.}
%\item {Worked on Hurricane mapping dashboard in ArcGIS that allowed analysts to monitor the path of hurricanes using data from National Hurricane Center (NHC)/National Oceanic and Atmospheric Administration (NOAA) and internal data.}
%\item {Working extracting structured energy loan data from unstructured 10-K SEC reports with PySpark in Databricks.}
%\item {Worked on a natural language processing (NLP)/Machine Learning (ML) project that analyzes tax documents from over 60,000 non-profits to determine whether they provide a financial service and if so, what type of financial service(s) they provide.}
%\item {Created, led, and presented to 100s of FDIC employees in a presentation titled Learning Lab 4: SQL Cross-Platform: How to use SQL queries across several different platforms and software from SAS to Python to Databricks.}
%\item {Participated as a panelist in several interviews.}
\item {Exploring utilizing AL/ML in the form of Large Language Models (LLMs) in Databricks and how it can be used with unstructured data such as summarizing information.}
%\item {Studying how Databricks can be leveraged, so that several core FDIC data sets (Research Information System [RIS], Statement of Deposits [SOD]) can be completely automated and ran in the cloud instead of locally by using data from the Federal Financial Institutions Examination Council's (FFIEC)/Central Data Repository (CDR) website.}
\end{cvitems}
}

%------------------------------------------------    

\cventry
{Management and Program Analyst (GS-14)} % Job title
{United States Citizenship and Immigration Services} % Organization
{Camp Spring, MD} % Location
{March 2019 - January 2022} % Date(s)
{ % Description(s) of tasks/responsibilities
\begin{cvitems}
\item {Worked on hundreds of data requests from Congress, the White House, Department of Homeland Security (DHS), and the public that aid in policymaking with same day turnarounds.}
\item {Led the analytical portion in updating the public facing USCIS front facing \href{https://egov.uscis.gov/processing-times/}{\textcolor{blue}{current processing times}} and the \href{https://egov.uscis.gov/processing-times/historic-pt}{\textcolor{blue}{historical processing times}} websites for all immigration and naturalization forms on a monthly basis.}
%\item {Led and implemented the new processing time methodology for the USCIS website; work with multiple stakeholders across the agency from operations to senior leadership.}
\item {Created, updated, and implemented explanations of the old and new processing times methodology on the \href{https://egov.uscis.gov/processing-times/more-info}{\textcolor{blue}{more info webpage}}.}
\item {Created and maintain multiple Tableau dashboards that summarizes critical information (receipts, approvals, denials, completions, pending, processing times) over 10+ fiscal years by location and form used by leadership.}
\item {Created and maintain reusable code in Databricks/Cloud using Spark SQL and Python that vastly improved upon currently used code in SAS/Oracle that is used by the team (NPD Macro, TPS Macro, RADPPT Queries).}
%\item {Maintain a GitHub repository of reusable code, methodologies, and documentations.}
\item {Investigated data anomalies in a database and worked with multiple teams to resolve this issue that affected 7+ million records.}
%\item {Forecasted processing times 5 years into the future using advanced analytics, which include economic models such as ARIMA, Holt's Winter, and simulations.}
%\item {Serve as a subject matter expert on various topics such as immigration processing times, Consideration of Deferred Action for Childhood Arrivals (DACA), Temporary Protected Status (TPS), and large data pulls that span multiple forms and time periods.}
%\item {Led the development, analysis, and response to an  {\href{https://www.oig.dhs.gov/sites/default/files/assets/2018-03/OIG-18-58-Mar18.pdf}{Office of Inspector General (OIG) Report}} to develop a better metric for processing times for green cards.}
\end{cvitems}
}

%------------------------------------------------

\cventry
{Economist (GS-13)} % Job title
{Social Security Administration} % Organization
{Woodlawn, MD} % Location
{November 2015 - March 2019} % Date(s)
{ % Description(s) of tasks/responsibilities
\begin{cvitems}
\item {Worked with the Office of Modeling (OM) to help improve an anti-fraud model using various machine learning models, which determines the expected value of recovering overpayments from claimants, with the potential to save the agency millions of dollars.}
\item {Developed a performance metric with inputs from SMEs for 100s of Social Security Administration's (SSA) employees working in the Office of Adjudication Operations (OAO) while utilizing resources such as the Enterprise Data Warehouse (EDW), SQL, SAS, and R with transactional data from Management Information Hearings Appeals and Litigation (MHAL) and Master Hearings and Appeals Operational Data Store (MHAODS).}
\item {Led the sensitive data wrangling and analysis for the Impact of Administrative Law Judge (ALJ) Decision Writer Instructions on Decision Writers' Efficiency and Quality Project, where data was collected through a survey given to decision writers in the San Francisco Region (Region IX).}
%\item {Worked on a confidential and controversial litigation project with management from the Office of Human Resources (OHR) that deals with addressing grievances from a Union concerning employee performance at SSA.}
%\item {Worked on a complex cross component project with SMEs and management from the Office of Adjudication and Review (ODAR) to help improve SSA’s operations and workload issues related to the hearing pending by transferring cases between hearing offices.}
%\item {Created forecasts in SAS to determine the trend on aged cases in different scenarios to aid the ACOSS and senior leadership to determine the proper hearings pending goal for the agency strategic plan.}
%\item {Coordinated and led 14 Data Science Technology Exchange Presentations to spread the importance of data analytics and data-driven decision making}
\end{cvitems} 
}

%------------------------------------------------

\cventry
{Senior Analyst} % Job title
{Summit Consulting LLC} % Organization
{Washington, D.C.} % Location
{June 2014 - October 2015} % Date(s)
{ % Description(s) of tasks/responsibilities
\begin{cvitems}
\item {Worked on a team with several PhDs at The U.S. Department of Treasury - Debt Management Services (DMS) to increase their delinquent debt collections and resolutions.}
%\item {Data wrangled internal sensitive and confidential transactional level data on 100,000s of debts across all federal agencies and external data from the American Community Survey (ACS) in Stata to create research datasets in preparation for conducting descriptive analysis and advanced analytical research.}
%\item {Utilized econometric models in Stata and data mining techniques in R (decision trees) to develop solutions on how DMS can improve the agency’s operating efficiencies and increase the number of delinquent debt collections and resolutions.}
\end{cvitems}
}

%------------------------------------------------

%\cventry
%{The Economic Research Group – Research Assistant} % Job title
%{The University of Chicago} % Organization
%{Chicago, IL} % Location
%{June 2007 - June 2012} % Date(s)
%{ % Description(s) of tasks/responsibilities
%	\begin{cvitems}
%		\item {Developed a proxy drive smartphone application which connects proxy driver and customer. Implemented overall Android application logic and wrote API server for community service, along with lead engineer who designed bidding protocol on raw socket and implemented API server for bidding.}
%		\item {\href{https://www.nber.org/system/files/working_papers/w23610/w23610.pdf}{An Analysis of the Memphis Nurse-Family Partnership Program}}
%		\item {\href{https://www.sciencedirect.com/science/article/abs/pii/B9780444534446000018}{Handbook of Personality Psychology and Economics}}
%		\item {\href{https://books.google.com/books?id=gJGPAgAAQBAJ\&pg=PR15\&lpg=PR15\&dq=terrance+oey\&source=bl\&ots=LzuT7k2Cpr\&sig=ACfU3U0mT4KgGjx2B5jl0Dp77qf58JkT8Q\&hl=en\&sa=X\&ved=2ahUKEwjvpsCsvav5AhX3M1kFHYBxCI44FBDoAXoECAIQAw#v=onepage\&q=terrance\%20oey\&f=false}{The Myth of Achievement Tests}}
%	\end{cvitems}
%}

%------------------------------------------------

%\cventry
%{Reverse Logistics Intern} % Job title
%{Cisco-Linksys} % Organization
%{Irvine, CA} % Location
%{June 2006 - September 2006} % Date(s)
%{ % Description(s) of tasks/responsibilities
%\begin{cvitems}
%\item {Developed a proxy drive smartphone application which connects proxy driver and customer. Implemented overall Android application logic and wrote API server for community service, along with lead engineer who designed bidding protocol on raw socket and implemented API server for bidding.}
%\end{cvitems}
%}

%------------------------------------------------

\end{cventries}